{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d5b7df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1e606e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "66e1cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./House_Rent_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "093a12b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posted On</th>\n",
       "      <th>BHK</th>\n",
       "      <th>Rent</th>\n",
       "      <th>Size</th>\n",
       "      <th>Floor</th>\n",
       "      <th>Area Type</th>\n",
       "      <th>Area Locality</th>\n",
       "      <th>City</th>\n",
       "      <th>Furnishing Status</th>\n",
       "      <th>Tenant Preferred</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Point of Contact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/18/2022</td>\n",
       "      <td>2</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>Ground out of 2</td>\n",
       "      <td>Super Area</td>\n",
       "      <td>Bandel</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>Bachelors/Family</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Contact Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/13/2022</td>\n",
       "      <td>2</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 out of 3</td>\n",
       "      <td>Super Area</td>\n",
       "      <td>Phool Bagan, Kankurgachi</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>Bachelors/Family</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Contact Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/16/2022</td>\n",
       "      <td>2</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1 out of 3</td>\n",
       "      <td>Super Area</td>\n",
       "      <td>Salt Lake City Sector 2</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Semi-Furnished</td>\n",
       "      <td>Bachelors/Family</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Contact Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/4/2022</td>\n",
       "      <td>2</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 out of 2</td>\n",
       "      <td>Super Area</td>\n",
       "      <td>Dumdum Park</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>Bachelors/Family</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Contact Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/9/2022</td>\n",
       "      <td>2</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1 out of 2</td>\n",
       "      <td>Carpet Area</td>\n",
       "      <td>South Dum Dum</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Unfurnished</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Contact Owner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Posted On  BHK     Rent  ...  Tenant Preferred Bathroom Point of Contact\n",
       "0  5/18/2022    2  10000.0  ...  Bachelors/Family      2.0    Contact Owner\n",
       "1  5/13/2022    2  20000.0  ...  Bachelors/Family      1.0    Contact Owner\n",
       "2  5/16/2022    2  17000.0  ...  Bachelors/Family      1.0    Contact Owner\n",
       "3   7/4/2022    2  10000.0  ...  Bachelors/Family      1.0    Contact Owner\n",
       "4   5/9/2022    2   7500.0  ...         Bachelors      1.0    Contact Owner\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "992c2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Posted On\", \"Area Locality\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "744b2985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4746 entries, 0 to 4745\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   BHK                4746 non-null   int64  \n",
      " 1   Rent               4741 non-null   float64\n",
      " 2   Size               4738 non-null   float64\n",
      " 3   Floor              4746 non-null   object \n",
      " 4   Area Type          4739 non-null   object \n",
      " 5   City               4746 non-null   object \n",
      " 6   Furnishing Status  4746 non-null   object \n",
      " 7   Tenant Preferred   4746 non-null   object \n",
      " 8   Bathroom           4742 non-null   float64\n",
      " 9   Point of Contact   4746 non-null   object \n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 370.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "a41c416b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BHK</th>\n",
       "      <th>Rent</th>\n",
       "      <th>Size</th>\n",
       "      <th>Bathroom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4746.000000</td>\n",
       "      <td>4.741000e+03</td>\n",
       "      <td>4738.000000</td>\n",
       "      <td>4742.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.083860</td>\n",
       "      <td>3.502340e+04</td>\n",
       "      <td>967.936049</td>\n",
       "      <td>1.965837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.832256</td>\n",
       "      <td>7.814214e+04</td>\n",
       "      <td>634.562635</td>\n",
       "      <td>0.884904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.200000e+03</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>550.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.600000e+04</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.300000e+04</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.500000e+06</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               BHK          Rent         Size     Bathroom\n",
       "count  4746.000000  4.741000e+03  4738.000000  4742.000000\n",
       "mean      2.083860  3.502340e+04   967.936049     1.965837\n",
       "std       0.832256  7.814214e+04   634.562635     0.884904\n",
       "min       1.000000  1.200000e+03    10.000000     1.000000\n",
       "25%       2.000000  1.000000e+04   550.000000     1.000000\n",
       "50%       2.000000  1.600000e+04   850.000000     2.000000\n",
       "75%       3.000000  3.300000e+04  1200.000000     2.000000\n",
       "max       6.000000  3.500000e+06  8000.000000    10.000000"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "1362ce93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BHK                  0\n",
       "Rent                 5\n",
       "Size                 8\n",
       "Floor                0\n",
       "Area Type            7\n",
       "City                 0\n",
       "Furnishing Status    0\n",
       "Tenant Preferred     0\n",
       "Bathroom             4\n",
       "Point of Contact     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7ef990fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "1d154919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of duplicate rows:\", df.duplicated().sum())\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "204b1e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in each column: 0\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of null values in each column:\", df.isnull().sum().sum())\n",
    "print(\"Number of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "b031d226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of numerical columns: 4\n",
      "Numerical columns: ['BHK', 'Rent', 'Size', 'Bathroom']\n"
     ]
    }
   ],
   "source": [
    "num_cols = df.select_dtypes(exclude=['object']).columns.tolist()\n",
    "print(\"Length of numerical columns:\", len(num_cols))\n",
    "print(\"Numerical columns:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "44aa2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers_iqr(df, cols):\n",
    "    df_capped = df.copy()\n",
    "    for col in cols:\n",
    "        Q1 = df_capped[col].quantile(0.25)\n",
    "        Q3 = df_capped[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df_capped[col] = df_capped[col].apply(\n",
    "            lambda x: lower_bound if x < lower_bound else upper_bound if x > upper_bound else x\n",
    "        )\n",
    "    return df_capped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "4bbc9948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               BHK          Rent         Size     Bathroom\n",
      "count  4686.000000   4686.000000  4686.000000  4686.000000\n",
      "mean      2.082053  24674.311353   933.925416     1.924242\n",
      "std       0.816087  19949.151318   508.414594     0.756418\n",
      "min       1.000000   1200.000000    10.000000     1.000000\n",
      "25%       2.000000  10000.000000   555.750000     1.000000\n",
      "50%       2.000000  16000.000000   850.000000     2.000000\n",
      "75%       3.000000  33000.000000  1200.000000     2.000000\n",
      "max       4.500000  67500.000000  2166.375000     3.500000\n"
     ]
    }
   ],
   "source": [
    "df = cap_outliers_iqr(df, num_cols)\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "93544131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of categorical columns: 6\n",
      "Categorical columns: ['Floor', 'Area Type', 'City', 'Furnishing Status', 'Tenant Preferred', 'Point of Contact']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Length of categorical columns:\", len(cat_cols))\n",
    "print(\"Categorical columns:\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3799a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floor\n",
      "1 out of 2         370\n",
      "Ground out of 2    336\n",
      "2 out of 3         310\n",
      "2 out of 4         302\n",
      "1 out of 3         289\n",
      "                  ... \n",
      "1 out of 11          1\n",
      "6 out of 29          1\n",
      "28 out of 31         1\n",
      "1 out of 15          1\n",
      "2 out of 11          1\n",
      "Name: count, Length: 480, dtype: int64\n",
      "Area Type\n",
      "Super Area     2414\n",
      "Carpet Area    2270\n",
      "Built Area        2\n",
      "Name: count, dtype: int64\n",
      "City\n",
      "Mumbai       968\n",
      "Chennai      880\n",
      "Bangalore    874\n",
      "Hyderabad    864\n",
      "Delhi        599\n",
      "Kolkata      501\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols[:3]:\n",
    "  print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "10cdea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Furnishing Status\n",
      "Semi-Furnished    2228\n",
      "Unfurnished       1786\n",
      "Furnished          672\n",
      "Name: count, dtype: int64\n",
      "Tenant Preferred\n",
      "Bachelors/Family    3397\n",
      "Bachelors            819\n",
      "Family               470\n",
      "Name: count, dtype: int64\n",
      "Point of Contact\n",
      "Contact Owner      3173\n",
      "Contact Agent      1512\n",
      "Contact Builder       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols[3:6]:\n",
    "  print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d4bdae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and clean both parts\n",
    "split_floor = df[\"Floor\"].str.split(\"out of\", expand=True)\n",
    "\n",
    "# Strip whitespace from both columns\n",
    "split_floor[0] = split_floor[0].fillna(\"\").str.strip()\n",
    "split_floor[1] = split_floor[1].fillna(\"\").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "54a51ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_floor[0] = split_floor[0].replace({\n",
    "    \"Ground\": \"0\",\n",
    "    \"Upper Basement\": \"-1\",\n",
    "    \"Basement\": \"-2\",\n",
    "    \"Lower Basement\": \"-3\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b5708074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Current Floor\"] = pd.to_numeric(split_floor[0], errors=\"coerce\").astype(\"Int64\")\n",
    "df[\"Total Floors\"] = pd.to_numeric(split_floor[1], errors=\"coerce\").astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "435f6d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.drop(columns=[\"Floor\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e16b78ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of categorical columns: 5\n",
      "Categorical columns: ['Area Type', 'City', 'Furnishing Status', 'Tenant Preferred', 'Point of Contact']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Length of categorical columns:\", len(cat_cols))\n",
    "print(\"Categorical columns:\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "0a8bbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "add68716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4682 entries, 0 to 4745\n",
      "Data columns (total 19 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   BHK                                4682 non-null   float64\n",
      " 1   Rent                               4682 non-null   float64\n",
      " 2   Size                               4682 non-null   float64\n",
      " 3   Bathroom                           4682 non-null   float64\n",
      " 4   Current Floor                      4682 non-null   Int64  \n",
      " 5   Total Floors                       4682 non-null   Int64  \n",
      " 6   Area Type_Carpet Area              4682 non-null   bool   \n",
      " 7   Area Type_Super Area               4682 non-null   bool   \n",
      " 8   City_Chennai                       4682 non-null   bool   \n",
      " 9   City_Delhi                         4682 non-null   bool   \n",
      " 10  City_Hyderabad                     4682 non-null   bool   \n",
      " 11  City_Kolkata                       4682 non-null   bool   \n",
      " 12  City_Mumbai                        4682 non-null   bool   \n",
      " 13  Furnishing Status_Semi-Furnished   4682 non-null   bool   \n",
      " 14  Furnishing Status_Unfurnished      4682 non-null   bool   \n",
      " 15  Tenant Preferred_Bachelors/Family  4682 non-null   bool   \n",
      " 16  Tenant Preferred_Family            4682 non-null   bool   \n",
      " 17  Point of Contact_Contact Builder   4682 non-null   bool   \n",
      " 18  Point of Contact_Contact Owner     4682 non-null   bool   \n",
      "dtypes: Int64(2), bool(13), float64(4)\n",
      "memory usage: 324.6 KB\n"
     ]
    }
   ],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "46a7702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "eb91f7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BHK</th>\n",
       "      <th>Rent</th>\n",
       "      <th>Size</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Current Floor</th>\n",
       "      <th>Total Floors</th>\n",
       "      <th>Area Type_Carpet Area</th>\n",
       "      <th>Area Type_Super Area</th>\n",
       "      <th>City_Chennai</th>\n",
       "      <th>City_Delhi</th>\n",
       "      <th>City_Hyderabad</th>\n",
       "      <th>City_Kolkata</th>\n",
       "      <th>City_Mumbai</th>\n",
       "      <th>Furnishing Status_Semi-Furnished</th>\n",
       "      <th>Furnishing Status_Unfurnished</th>\n",
       "      <th>Tenant Preferred_Bachelors/Family</th>\n",
       "      <th>Tenant Preferred_Family</th>\n",
       "      <th>Point of Contact_Contact Builder</th>\n",
       "      <th>Point of Contact_Contact Owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BHK  ...  Point of Contact_Contact Owner\n",
       "0  2.0  ...                            True\n",
       "2  2.0  ...                            True\n",
       "4  2.0  ...                            True\n",
       "5  2.0  ...                            True\n",
       "6  2.0  ...                           False\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "6ead3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numerical_cols = [\"BHK\", \"Size\", \"Bathroom\", \"Current Floor\", \"Total Floors\"]\n",
    "df_encoded[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "139223fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(\"Rent\", axis=1)\n",
    "y = df_encoded[\"Rent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "45e20840",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9973e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "497a7217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Linear Regression\n",
      "R2 Score: 0.7861\n",
      "MSE: 93239157.82\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "model_results[\"LinearRegression\"] = {\"R2\": r2, \"MSE\": mse}\n",
    "print(f\"🔹 Linear Regression\\nR2 Score: {r2:.4f}\\nMSE: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "4c95afd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2 Score: 0.7796790549441979\n",
      "Test R2 Score: 0.7860553276097247\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Train R2 Score:\", r2_score(y_train, y_train_pred))\n",
    "print(\"Test R2 Score:\", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e348a271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 SVR\n",
      "Best Params: {'C': 10, 'epsilon': 0.2, 'kernel': 'rbf'}\n",
      "R2 Score: -0.0126\n",
      "MSE: 441315814.10\n"
     ]
    }
   ],
   "source": [
    "# SVR Regression\n",
    "param_grid = {\n",
    "    \"C\": [1, 10],\n",
    "    \"epsilon\": [0.1, 0.2],\n",
    "    \"kernel\": [\"rbf\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid, cv=3, scoring=\"r2\", n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "model_results[\"SVR\"] = {\"R2\": r2, \"MSE\": mse}\n",
    "print(f\"🔹 SVR\\nBest Params: {grid.best_params_}\\nR2 Score: {r2:.4f}\\nMSE: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "72494b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2 Score: 0.002895586636805225\n",
      "Test R2 Score: -0.012634278093251794\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = grid.predict(X_train)\n",
    "y_test_pred = grid.predict(X_test)\n",
    "\n",
    "print(\"Train R2 Score:\", r2_score(y_train, y_train_pred))\n",
    "print(\"Test R2 Score:\", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "3349b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 KNN\n",
      "Best Params: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "R2 Score: 0.8126\n",
      "MSE: 81670731.36\n"
     ]
    }
   ],
   "source": [
    "# KNN Regression\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [3, 5, 7],\n",
    "    \"weights\": [\"uniform\", \"distance\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsRegressor(), param_grid, cv=3, scoring=\"r2\", n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "model_results[\"KNN\"] = {\"R2\": r2, \"MSE\": mse}\n",
    "print(f\"🔹 KNN\\nBest Params: {grid.best_params_}\\nR2 Score: {r2:.4f}\\nMSE: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "180f8f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2 Score: 0.9978941712537969\n",
      "Test R2 Score: 0.8126000033332346\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = grid.predict(X_train)\n",
    "y_test_pred = grid.predict(X_test)\n",
    "\n",
    "print(\"Train R2 Score:\", r2_score(y_train, y_train_pred))\n",
    "print(\"Test R2 Score:\", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "408c543d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Decision Tree\n",
      "Best Params: {'max_depth': 5, 'min_samples_split': 5}\n",
      "R2 Score: 0.8216\n",
      "MSE: 77736125.25\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regression\n",
    "param_grid = {\n",
    "    \"max_depth\": [5, 10, None],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=3, scoring=\"r2\", n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "model_results[\"DecisionTree\"] = {\"R2\": r2, \"MSE\": mse}\n",
    "print(f\"🔹 Decision Tree\\nBest Params: {grid.best_params_}\\nR2 Score: {r2:.4f}\\nMSE: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b68acf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2 Score: 0.8195783261284956\n",
      "Test R2 Score: 0.8216282703730831\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = grid.predict(X_train)\n",
    "y_test_pred = grid.predict(X_test)\n",
    "\n",
    "print(\"Train R2 Score:\", r2_score(y_train, y_train_pred))\n",
    "print(\"Test R2 Score:\", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ed4f56ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Random Forest\n",
      "Best Params: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "R2 Score: 0.8488\n",
      "MSE: 65872879.81\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regression\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100],\n",
    "    \"max_depth\": [None, 10],\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(RandomForestRegressor(), param_grid, cv=3, scoring=\"r2\", n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "model_results[\"RandomForest\"] = {\"R2\": r2, \"MSE\": mse}\n",
    "print(f\"🔹 Random Forest\\nBest Params: {grid.best_params_}\\nR2 Score: {r2:.4f}\\nMSE: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "b0608084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2 Score: 0.9226349680133248\n",
      "Test R2 Score: 0.8488494317186301\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = grid.predict(X_train)\n",
    "y_test_pred = grid.predict(X_test)\n",
    "\n",
    "print(\"Train R2 Score:\", r2_score(y_train, y_train_pred))\n",
    "print(\"Test R2 Score:\", r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "72216e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔸 Compare all models:\n",
      "                        R2           MSE\n",
      "LinearRegression  0.786055  9.323916e+07\n",
      "SVR              -0.012634  4.413158e+08\n",
      "KNN               0.812600  8.167073e+07\n",
      "DecisionTree      0.821628  7.773613e+07\n",
      "RandomForest      0.848849  6.587288e+07\n"
     ]
    }
   ],
   "source": [
    "print(\"🔸 Compare all models:\")\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "543a8985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_analysis(X_train, y_train, X_test, y_test):\n",
    "    # Define scalers\n",
    "    scalers = {\n",
    "        \"StandardScaler\": StandardScaler(),\n",
    "        \"MinMaxScaler\": MinMaxScaler(),\n",
    "        \"RobustScaler\": RobustScaler()\n",
    "    }\n",
    "\n",
    "    # Define models\n",
    "    base_models = {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"SVM Regression\": SVR(),\n",
    "        \"KNN Regression\": KNeighborsRegressor(),\n",
    "        \"DecisionTree\": DecisionTreeRegressor(),\n",
    "        \"RandomForest\": RandomForestRegressor(),\n",
    "    }\n",
    "\n",
    "    # Ensemble models\n",
    "    ensemble_models = {\n",
    "        \"Voting\": VotingRegressor([(\"lr\", LinearRegression()), (\"dt\", DecisionTreeRegressor()), (\"rf\", RandomForestRegressor())]),\n",
    "        \"Bagging\": BaggingRegressor(RandomForestRegressor(), n_estimators=50),\n",
    "        \"Boosting\": GradientBoostingRegressor(n_estimators=100),\n",
    "        \"Stacking\": StackingRegressor(estimators=[\n",
    "            (\"lr\", LinearRegression()),\n",
    "            (\"svm\", SVR()),\n",
    "            (\"rf\", RandomForestRegressor())\n",
    "        ], final_estimator=LinearRegression()),\n",
    "    }\n",
    "\n",
    "    models_with_params = {**base_models, **ensemble_models}\n",
    "\n",
    "    param_grid_all = {\n",
    "      \"SVM Regression\": {\n",
    "          \"model__C\": [1, 10],\n",
    "          \"model__kernel\": [\"rbf\"],\n",
    "          \"model__epsilon\": [0.05, 0.1]\n",
    "      },\n",
    "\n",
    "      \"KNN Regression\": {\n",
    "          \"model__n_neighbors\": [7, 9],\n",
    "          \"model__weights\": [\"distance\"],\n",
    "          \"model__p\": [2]\n",
    "      },\n",
    "\n",
    "      \"DecisionTree\": {\n",
    "          \"model__max_depth\": [3, 5],\n",
    "          \"model__min_samples_split\": [5, 10],\n",
    "          \"model__min_samples_leaf\": [3, 5]\n",
    "      },\n",
    "\n",
    "      \"RandomForest\": {\n",
    "          \"model__n_estimators\": [100],\n",
    "          \"model__max_depth\": [6],\n",
    "          \"model__min_samples_split\": [5],\n",
    "          \"model__min_samples_leaf\": [2]\n",
    "      },\n",
    "\n",
    "      \"Bagging\": {\n",
    "          \"model__n_estimators\": [100],\n",
    "          \"model__max_samples\": [0.8],\n",
    "          \"model__max_features\": [0.8]\n",
    "      },\n",
    "\n",
    "      \"Boosting\": {\n",
    "          \"model__n_estimators\": [100],\n",
    "          \"model__learning_rate\": [0.05],\n",
    "          \"model__max_depth\": [3]\n",
    "      }\n",
    "  }\n",
    "\n",
    "\n",
    "    feature_selector = SelectKBest(score_func=f_regression, k='all')\n",
    "    models_need_y_scaling = [\"SVM Regression\", \"KNN Regression\"]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for scaler_name, scaler in scalers.items():\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        for model_name, model in models_with_params.items():\n",
    "            pipe = Pipeline([\n",
    "                ('select', feature_selector),\n",
    "                ('model', model)\n",
    "            ])\n",
    "\n",
    "            param_grid = param_grid_all.get(model_name, {})\n",
    "            grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "            use_y_scaling = model_name in models_need_y_scaling\n",
    "            y_scaler = StandardScaler()\n",
    "\n",
    "            if use_y_scaling:\n",
    "                y_train_np = y_train.to_numpy().reshape(-1, 1)\n",
    "                y_train_scaled = y_scaler.fit_transform(y_train_np).ravel()\n",
    "\n",
    "                grid.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "                y_pred_scaled = grid.predict(X_test_scaled)\n",
    "                y_pred = y_scaler.inverse_transform(np.array(y_pred_scaled).reshape(-1, 1)).ravel()\n",
    "\n",
    "                y_train_pred_scaled = grid.predict(X_train_scaled)\n",
    "                y_train_pred = y_scaler.inverse_transform(np.array(y_train_pred_scaled).reshape(-1, 1)).ravel()\n",
    "            else:\n",
    "                grid.fit(X_train_scaled, y_train)\n",
    "                y_pred = grid.predict(X_test_scaled)\n",
    "                y_train_pred = grid.predict(X_train_scaled)\n",
    "\n",
    "            results.append({\n",
    "                \"Scaler\": scaler_name,\n",
    "                \"Model\": model_name,\n",
    "                \"Best Params\": grid.best_params_,\n",
    "                \"R2 Score\": r2_score(y_test, y_pred),\n",
    "                \"MSE\": mean_squared_error(y_test, y_pred),\n",
    "                \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "                \"Train Score\": r2_score(y_train, y_train_pred),\n",
    "                \"Test Score\": r2_score(y_test, y_pred)\n",
    "            })\n",
    "\n",
    "    # Create DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results_sorted = df_results.sort_values(by=\"R2 Score\", ascending=False)\n",
    "    df_results_sorted[\"R2 Score\"] = df_results_sorted[\"R2 Score\"].apply(lambda x: round(x, 4))\n",
    "    df_results_sorted[\"MSE\"] = df_results_sorted[\"MSE\"].apply(lambda x: f\"{x:.2e}\")\n",
    "    df_results_sorted[\"MAE\"] = df_results_sorted[\"MAE\"].apply(lambda x: f\"{x:,.2f}\")\n",
    "    df_display = df_results_sorted[[\"Model\", \"Scaler\", \"R2 Score\", \"MSE\", \"MAE\", \"Best Params\"]]\n",
    "\n",
    "    print(\"\\n📊 🔝 Top Results by R² Score:\\n\")\n",
    "    print(df_display.to_string(index=False))\n",
    "\n",
    "    # Average performance per model\n",
    "    df_avg = df_results.copy()\n",
    "    model_avg = df_avg.groupby(\"Model\")[[\"R2 Score\", \"MSE\", \"MAE\"]].mean().reset_index()\n",
    "    model_avg = model_avg.sort_values(by=\"R2 Score\", ascending=False)\n",
    "    print(\"\\n📌 Average Performance per Model:\\n\")\n",
    "    print(model_avg.to_string(index=False, formatters={\n",
    "        \"R2 Score\": \"{:.4f}\".format,\n",
    "        \"MSE\": \"{:.2e}\".format,\n",
    "        \"MAE\": \"{:,.2f}\".format\n",
    "    }))\n",
    "\n",
    "    # Average performance per scaler\n",
    "    scaler_avg = df_avg.groupby(\"Scaler\")[[\"R2 Score\", \"MSE\", \"MAE\"]].mean().reset_index()\n",
    "    scaler_avg = scaler_avg.sort_values(by=\"R2 Score\", ascending=False)\n",
    "    print(\"\\n📌 Average Performance per Scaler:\\n\")\n",
    "    print(scaler_avg.to_string(index=False, formatters={\n",
    "        \"R2 Score\": \"{:.4f}\".format,\n",
    "        \"MSE\": \"{:.2e}\".format,\n",
    "        \"MAE\": \"{:,.2f}\".format\n",
    "    }))\n",
    "\n",
    "    # Scaler insights\n",
    "    for scaler in df_avg[\"Scaler\"].unique():\n",
    "        subset = df_avg[df_avg[\"Scaler\"] == scaler]\n",
    "        print(f\"\\n📊 Scaler Results: {scaler}\\n\")\n",
    "        print(\"🔺 Highest R²:\")\n",
    "        print(subset.loc[subset[\"R2 Score\"].idxmax()][[\"Model\", \"R2 Score\", \"MSE\", \"MAE\"]].to_string())\n",
    "        print(\"\\n🔻 Lowest R²:\")\n",
    "        print(subset.loc[subset[\"R2 Score\"].idxmin()][[\"Model\", \"R2 Score\", \"MSE\", \"MAE\"]].to_string())\n",
    "        print(\"\\n🔻 Lowest MSE:\")\n",
    "        print(subset.loc[subset[\"MSE\"].idxmin()][[\"Model\", \"R2 Score\", \"MSE\", \"MAE\"]].to_string())\n",
    "        print(\"\\n🔻 Lowest MAE:\")\n",
    "        print(subset.loc[subset[\"MAE\"].idxmin()][[\"Model\", \"R2 Score\", \"MSE\", \"MAE\"]].to_string())\n",
    "\n",
    "    # Train vs Test R² scores\n",
    "    print(\"\\n🧪 Train vs Test R² Score Comparison:\\n\")\n",
    "    for scaler_name, scaler in scalers.items():\n",
    "        print(f\"\\n🚀 Scaler: {scaler_name}\")\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        for model_name, model in models_with_params.items():\n",
    "            model_clone = clone(model)\n",
    "            use_y_scaling = model_name in models_need_y_scaling\n",
    "            if use_y_scaling:\n",
    "                y_train_scaled = y_scaler.fit_transform(y_train.to_numpy().reshape(-1, 1)).ravel()\n",
    "                model_clone.fit(X_train_scaled, y_train_scaled)\n",
    "                train_score = r2_score(y_train, y_scaler.inverse_transform(model_clone.predict(X_train_scaled).reshape(-1, 1)).ravel())\n",
    "                test_score = r2_score(y_test, y_scaler.inverse_transform(model_clone.predict(X_test_scaled).reshape(-1, 1)).ravel())\n",
    "            else:\n",
    "                model_clone.fit(X_train_scaled, y_train)\n",
    "                train_score = model_clone.score(X_train_scaled, y_train)\n",
    "                test_score = model_clone.score(X_test_scaled, y_test)\n",
    "            print(f\"🔹 {model_name:18} | Train R²: {train_score:.4f} | Test R²: {test_score:.4f}\")\n",
    "\n",
    "    # Best result per model\n",
    "    best_per_model = df_results.loc[df_results.groupby(\"Model\")[\"R2 Score\"].idxmax()]\n",
    "    best_per_model = best_per_model.sort_values(by=\"R2 Score\", ascending=False)\n",
    "    print(\"📈 Best result for each model:\\n\")\n",
    "    for _, row in best_per_model.iterrows():\n",
    "        print(f\"🧠 Model        : {row['Model']}\")\n",
    "        print(f\"   🔧 Scaler    : {row['Scaler']}\")\n",
    "        print(f\"   🎯 R2 Score  : {row['R2 Score']:.4f}\")\n",
    "        print(f\"   🧪 MSE       : {row['MSE']:.2f}\")\n",
    "        print(f\"   📉 MAE       : {row['MAE']:.2f}\")\n",
    "        print(f\"   ⚙️ Best Params: {row['Best Params']}\\n\")\n",
    "\n",
    "    return df_results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "60fa09b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 🔝 Top Results by R² Score:\n",
      "\n",
      "           Model         Scaler  R2 Score      MSE      MAE                                                                                                      Best Params\n",
      "         Bagging StandardScaler    0.8507 6.51e+07 5,438.19                              {'model__max_features': 0.8, 'model__max_samples': 0.8, 'model__n_estimators': 100}\n",
      "  SVM Regression StandardScaler    0.8495 6.56e+07 5,216.76                                                   {'model__C': 1, 'model__epsilon': 0.1, 'model__kernel': 'rbf'}\n",
      "        Stacking   RobustScaler    0.8493 6.57e+07 5,427.29                                                                                                               {}\n",
      "         Bagging   RobustScaler    0.8489 6.58e+07 5,477.61                              {'model__max_features': 0.8, 'model__max_samples': 0.8, 'model__n_estimators': 100}\n",
      "         Bagging   MinMaxScaler    0.8481 6.62e+07 5,499.52                              {'model__max_features': 0.8, 'model__max_samples': 0.8, 'model__n_estimators': 100}\n",
      "        Stacking StandardScaler    0.8477 6.64e+07 5,443.60                                                                                                               {}\n",
      "        Stacking   MinMaxScaler    0.8470 6.67e+07 5,439.99                                                                                                               {}\n",
      "    RandomForest   RobustScaler    0.8445 6.78e+07 5,340.36 {'model__max_depth': 6, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "    RandomForest   MinMaxScaler    0.8436 6.82e+07 5,368.04 {'model__max_depth': 6, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "    RandomForest StandardScaler    0.8431 6.84e+07 5,374.53 {'model__max_depth': 6, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "  SVM Regression   MinMaxScaler    0.8374 7.08e+07 5,459.95                                                   {'model__C': 1, 'model__epsilon': 0.1, 'model__kernel': 'rbf'}\n",
      "  SVM Regression   RobustScaler    0.8358 7.16e+07 5,476.57                                                  {'model__C': 10, 'model__epsilon': 0.1, 'model__kernel': 'rbf'}\n",
      "        Boosting   RobustScaler    0.8345 7.21e+07 5,594.76                                {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
      "        Boosting StandardScaler    0.8345 7.21e+07 5,594.52                                {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
      "        Boosting   MinMaxScaler    0.8345 7.21e+07 5,595.23                                {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
      "          Voting   MinMaxScaler    0.8292 7.44e+07 5,766.92                                                                                                               {}\n",
      "          Voting StandardScaler    0.8273 7.52e+07 5,773.99                                                                                                               {}\n",
      "          Voting   RobustScaler    0.8270 7.54e+07 5,791.87                                                                                                               {}\n",
      "    DecisionTree StandardScaler    0.8251 7.62e+07 5,718.37                             {'model__max_depth': 5, 'model__min_samples_leaf': 5, 'model__min_samples_split': 5}\n",
      "    DecisionTree   RobustScaler    0.8251 7.62e+07 5,718.37                             {'model__max_depth': 5, 'model__min_samples_leaf': 5, 'model__min_samples_split': 5}\n",
      "    DecisionTree   MinMaxScaler    0.8251 7.62e+07 5,718.37                             {'model__max_depth': 5, 'model__min_samples_leaf': 5, 'model__min_samples_split': 5}\n",
      "  KNN Regression StandardScaler    0.8106 8.25e+07 5,848.14                                           {'model__n_neighbors': 9, 'model__p': 2, 'model__weights': 'distance'}\n",
      "  KNN Regression   MinMaxScaler    0.8040 8.54e+07 5,959.06                                           {'model__n_neighbors': 9, 'model__p': 2, 'model__weights': 'distance'}\n",
      "  KNN Regression   RobustScaler    0.7911 9.10e+07 6,285.00                                           {'model__n_neighbors': 9, 'model__p': 2, 'model__weights': 'distance'}\n",
      "LinearRegression StandardScaler    0.7861 9.32e+07 6,974.15                                                                                                               {}\n",
      "LinearRegression   MinMaxScaler    0.7861 9.32e+07 6,974.15                                                                                                               {}\n",
      "LinearRegression   RobustScaler    0.7861 9.32e+07 6,974.15                                                                                                               {}\n",
      "\n",
      "📌 Average Performance per Model:\n",
      "\n",
      "           Model R2 Score      MSE      MAE\n",
      "         Bagging   0.8492 6.57e+07 5,471.77\n",
      "        Stacking   0.8480 6.62e+07 5,436.96\n",
      "    RandomForest   0.8438 6.81e+07 5,360.98\n",
      "  SVM Regression   0.8409 6.93e+07 5,384.43\n",
      "        Boosting   0.8345 7.21e+07 5,594.84\n",
      "          Voting   0.8278 7.50e+07 5,777.60\n",
      "    DecisionTree   0.8251 7.62e+07 5,718.37\n",
      "  KNN Regression   0.8019 8.63e+07 6,030.73\n",
      "LinearRegression   0.7861 9.32e+07 6,974.15\n",
      "\n",
      "📌 Average Performance per Scaler:\n",
      "\n",
      "        Scaler R2 Score      MSE      MAE\n",
      "StandardScaler   0.8305 7.39e+07 5,709.14\n",
      "  MinMaxScaler   0.8283 7.48e+07 5,753.47\n",
      "  RobustScaler   0.8269 7.54e+07 5,787.33\n",
      "\n",
      "📊 Scaler Results: StandardScaler\n",
      "\n",
      "🔺 Highest R²:\n",
      "Model              Bagging\n",
      "R2 Score           0.85071\n",
      "MSE         65061996.43339\n",
      "MAE             5438.19384\n",
      "\n",
      "🔻 Lowest R²:\n",
      "Model       LinearRegression\n",
      "R2 Score            0.786055\n",
      "MSE          93239157.820217\n",
      "MAE              6974.150926\n",
      "\n",
      "🔻 Lowest MSE:\n",
      "Model              Bagging\n",
      "R2 Score           0.85071\n",
      "MSE         65061996.43339\n",
      "MAE             5438.19384\n",
      "\n",
      "🔻 Lowest MAE:\n",
      "Model        SVM Regression\n",
      "R2 Score           0.849498\n",
      "MSE         65590422.259993\n",
      "MAE             5216.756539\n",
      "\n",
      "📊 Scaler Results: MinMaxScaler\n",
      "\n",
      "🔺 Highest R²:\n",
      "Model               Bagging\n",
      "R2 Score           0.848052\n",
      "MSE         66220228.824919\n",
      "MAE             5499.521353\n",
      "\n",
      "🔻 Lowest R²:\n",
      "Model       LinearRegression\n",
      "R2 Score            0.786055\n",
      "MSE          93239157.820217\n",
      "MAE              6974.150926\n",
      "\n",
      "🔻 Lowest MSE:\n",
      "Model               Bagging\n",
      "R2 Score           0.848052\n",
      "MSE         66220228.824919\n",
      "MAE             5499.521353\n",
      "\n",
      "🔻 Lowest MAE:\n",
      "Model          RandomForest\n",
      "R2 Score           0.843579\n",
      "MSE         68169848.016248\n",
      "MAE             5368.035391\n",
      "\n",
      "📊 Scaler Results: RobustScaler\n",
      "\n",
      "🔺 Highest R²:\n",
      "Model              Stacking\n",
      "R2 Score           0.849333\n",
      "MSE         65662327.078757\n",
      "MAE             5427.291413\n",
      "\n",
      "🔻 Lowest R²:\n",
      "Model       LinearRegression\n",
      "R2 Score            0.786055\n",
      "MSE          93239157.820217\n",
      "MAE              6974.150926\n",
      "\n",
      "🔻 Lowest MSE:\n",
      "Model              Stacking\n",
      "R2 Score           0.849333\n",
      "MSE         65662327.078757\n",
      "MAE             5427.291413\n",
      "\n",
      "🔻 Lowest MAE:\n",
      "Model          RandomForest\n",
      "R2 Score           0.844534\n",
      "MSE         67753547.019101\n",
      "MAE             5340.361168\n",
      "\n",
      "🧪 Train vs Test R² Score Comparison:\n",
      "\n",
      "\n",
      "🚀 Scaler: StandardScaler\n",
      "🔹 LinearRegression   | Train R²: 0.7797 | Test R²: 0.7861\n",
      "🔹 SVM Regression     | Train R²: 0.8642 | Test R²: 0.8495\n",
      "🔹 KNN Regression     | Train R²: 0.8613 | Test R²: 0.7985\n",
      "🔹 DecisionTree       | Train R²: 0.9979 | Test R²: 0.6960\n",
      "🔹 RandomForest       | Train R²: 0.9737 | Test R²: 0.8464\n",
      "🔹 Voting             | Train R²: 0.9589 | Test R²: 0.8241\n",
      "🔹 Bagging            | Train R²: 0.9390 | Test R²: 0.8521\n",
      "🔹 Boosting           | Train R²: 0.8566 | Test R²: 0.8409\n",
      "🔹 Stacking           | Train R²: 0.9444 | Test R²: 0.8493\n",
      "\n",
      "🚀 Scaler: MinMaxScaler\n",
      "🔹 LinearRegression   | Train R²: 0.7797 | Test R²: 0.7861\n",
      "🔹 SVM Regression     | Train R²: 0.8441 | Test R²: 0.8374\n",
      "🔹 KNN Regression     | Train R²: 0.8520 | Test R²: 0.7879\n",
      "🔹 DecisionTree       | Train R²: 0.9979 | Test R²: 0.6822\n",
      "🔹 RandomForest       | Train R²: 0.9734 | Test R²: 0.8434\n",
      "🔹 Voting             | Train R²: 0.9592 | Test R²: 0.8304\n",
      "🔹 Bagging            | Train R²: 0.9382 | Test R²: 0.8529\n",
      "🔹 Boosting           | Train R²: 0.8566 | Test R²: 0.8408\n",
      "🔹 Stacking           | Train R²: 0.9444 | Test R²: 0.8505\n",
      "\n",
      "🚀 Scaler: RobustScaler\n",
      "🔹 LinearRegression   | Train R²: 0.7797 | Test R²: 0.7861\n",
      "🔹 SVM Regression     | Train R²: 0.8421 | Test R²: 0.8297\n",
      "🔹 KNN Regression     | Train R²: 0.8511 | Test R²: 0.7821\n",
      "🔹 DecisionTree       | Train R²: 0.9979 | Test R²: 0.6655\n",
      "🔹 RandomForest       | Train R²: 0.9739 | Test R²: 0.8459\n",
      "🔹 Voting             | Train R²: 0.9591 | Test R²: 0.8261\n",
      "🔹 Bagging            | Train R²: 0.9377 | Test R²: 0.8528\n",
      "🔹 Boosting           | Train R²: 0.8566 | Test R²: 0.8408\n",
      "🔹 Stacking           | Train R²: 0.9434 | Test R²: 0.8481\n",
      "📈 Best result for each model:\n",
      "\n",
      "🧠 Model        : Bagging\n",
      "   🔧 Scaler    : StandardScaler\n",
      "   🎯 R2 Score  : 0.8507\n",
      "   🧪 MSE       : 65061996.43\n",
      "   📉 MAE       : 5438.19\n",
      "   ⚙️ Best Params: {'model__max_features': 0.8, 'model__max_samples': 0.8, 'model__n_estimators': 100}\n",
      "\n",
      "🧠 Model        : SVM Regression\n",
      "   🔧 Scaler    : StandardScaler\n",
      "   🎯 R2 Score  : 0.8495\n",
      "   🧪 MSE       : 65590422.26\n",
      "   📉 MAE       : 5216.76\n",
      "   ⚙️ Best Params: {'model__C': 1, 'model__epsilon': 0.1, 'model__kernel': 'rbf'}\n",
      "\n",
      "🧠 Model        : Stacking\n",
      "   🔧 Scaler    : RobustScaler\n",
      "   🎯 R2 Score  : 0.8493\n",
      "   🧪 MSE       : 65662327.08\n",
      "   📉 MAE       : 5427.29\n",
      "   ⚙️ Best Params: {}\n",
      "\n",
      "🧠 Model        : RandomForest\n",
      "   🔧 Scaler    : RobustScaler\n",
      "   🎯 R2 Score  : 0.8445\n",
      "   🧪 MSE       : 67753547.02\n",
      "   📉 MAE       : 5340.36\n",
      "   ⚙️ Best Params: {'model__max_depth': 6, 'model__min_samples_leaf': 2, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n",
      "\n",
      "🧠 Model        : Boosting\n",
      "   🔧 Scaler    : RobustScaler\n",
      "   🎯 R2 Score  : 0.8345\n",
      "   🧪 MSE       : 72124351.95\n",
      "   📉 MAE       : 5594.76\n",
      "   ⚙️ Best Params: {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
      "\n",
      "🧠 Model        : Voting\n",
      "   🔧 Scaler    : MinMaxScaler\n",
      "   🎯 R2 Score  : 0.8292\n",
      "   🧪 MSE       : 74445349.53\n",
      "   📉 MAE       : 5766.92\n",
      "   ⚙️ Best Params: {}\n",
      "\n",
      "🧠 Model        : DecisionTree\n",
      "   🔧 Scaler    : StandardScaler\n",
      "   🎯 R2 Score  : 0.8251\n",
      "   🧪 MSE       : 76212096.53\n",
      "   📉 MAE       : 5718.37\n",
      "   ⚙️ Best Params: {'model__max_depth': 5, 'model__min_samples_leaf': 5, 'model__min_samples_split': 5}\n",
      "\n",
      "🧠 Model        : KNN Regression\n",
      "   🔧 Scaler    : StandardScaler\n",
      "   🎯 R2 Score  : 0.8106\n",
      "   🧪 MSE       : 82539749.21\n",
      "   📉 MAE       : 5848.14\n",
      "   ⚙️ Best Params: {'model__n_neighbors': 9, 'model__p': 2, 'model__weights': 'distance'}\n",
      "\n",
      "🧠 Model        : LinearRegression\n",
      "   🔧 Scaler    : StandardScaler\n",
      "   🎯 R2 Score  : 0.7861\n",
      "   🧪 MSE       : 93239157.82\n",
      "   📉 MAE       : 6974.15\n",
      "   ⚙️ Best Params: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_results = regression_analysis(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
